{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Punto (a): Separar el Conjunto de Datos de Entrenamiento y Validación\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1698088971691
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Message: Running rslex direct volume mount: RSLEX_DIRECT_VOLUME_MOUNT=None, RSLEX_DIRECT_VOLUME_WRITABLE_MOUNT=None, enable_rslex_mount=None\n",
            "Payload: {\"pid\": 28596, \"rslex_version\": \"2.19.6\", \"version\": \"4.12.5\"}\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Workspace, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "# Carga el dataset desde el workspace de Azure\n",
        "workspace = Workspace.from_config()\n",
        "dataset = Dataset.get_by_name(workspace, name='processed_data')\n",
        "\n",
        "# Montar el dataset y leerlo con pandas\n",
        "mount_context = dataset.mount('./dataset_mount')\n",
        "mount_context.start()\n",
        "\n",
        "df = pd.read_csv('./dataset_mount/processed_data.csv')\n",
        "\n",
        "mount_context.stop()\n",
        "\n",
        "# Divide el dataframe en conjuntos de entrenamiento y validación\n",
        "train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convertir los dataframes de entrenamiento y validación de nuevo a datasets de Azure para usarlos más adelante\n",
        "# Para ello, primero tendrías que guardar los dataframes como CSV y luego subirlos a tu datastore\n",
        "train_df.to_csv('./train_data/train_data.csv', index=False)\n",
        "valid_df.to_csv('./valid_data/valid_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1698089684422
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "paths:\n",
            "- file: file:///mnt/batch/tasks/shared/LS_root/mounts/clusters/primer-proyecto/code/Users/mauricio.quezada/train_data.csv\n",
            "transformations:\n",
            "- read_delimited:\n",
            "    delimiter: ','\n",
            "    empty_as_string: false\n",
            "    encoding: utf8\n",
            "    header: all_files_same_headers\n",
            "    include_path_column: false\n",
            "    infer_column_types: true\n",
            "    partition_size: 20971520\n",
            "    path_column: Path\n",
            "    support_multi_line: false\n",
            "type: mltable\n",
            "\n",
            "paths:\n",
            "- file: file:///mnt/batch/tasks/shared/LS_root/mounts/clusters/primer-proyecto/code/Users/mauricio.quezada/train_data.csv\n",
            "transformations:\n",
            "- read_delimited:\n",
            "    delimiter: ','\n",
            "    empty_as_string: false\n",
            "    encoding: utf8\n",
            "    header: all_files_same_headers\n",
            "    include_path_column: false\n",
            "    infer_column_types: true\n",
            "    partition_size: 20971520\n",
            "    path_column: Path\n",
            "    support_multi_line: false\n",
            "type: mltable\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Engine process terminated with returncode=-2\n"
          ]
        }
      ],
      "source": [
        "import mltable\n",
        "\n",
        "train_path = [\n",
        "    {\n",
        "        \"file\": \"train_data.csv\"\n",
        "    }\n",
        "]\n",
        "\n",
        "train_data_mltable = mltable.from_delimited_files(paths=train_path)\n",
        "train_data_mltable.save(\"./train_data\")\n",
        "\n",
        "validation_path = [\n",
        "    {\n",
        "        \"file\": \"valid_data.csv\"\n",
        "    }\n",
        "]\n",
        "\n",
        "validation_data_mltable = mltable.from_delimited_files(paths=validation_path)\n",
        "validation_data_mltable.save(\"./valid_data\")\n",
        "\n",
        "print(train_data_mltable)\n",
        "print(validation_data_mltable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Punto (b): Crear un Cluster de Computación en Azure ML\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1698089140535
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "InProgress..\n",
            "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
            "Succeeded........................\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Definir la configuración del cluster\n",
        "cluster_name = \"co2-cluster\"\n",
        "try:\n",
        "    cluster = ComputeTarget(workspace=workspace, name=cluster_name)\n",
        "    print(f\"Found existing cluster: {cluster_name}\")\n",
        "except ComputeTargetException:\n",
        "    config = AmlCompute.provisioning_configuration(vm_size='Standard_D2_v2', \n",
        "                                                   max_nodes=4, \n",
        "                                                   min_nodes=1)\n",
        "    cluster = ComputeTarget.create(workspace, cluster_name, config)\n",
        "\n",
        "cluster.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "JUSTIFICACION:\n",
        "\n",
        "    *Para este apartado utilizamos un mínimo de 1 y máximo 4 nodos, debido a que lo vimos más que suficiente para el trabajo requerido.\n",
        "    *El recurso que se utilizó, es la libreria de MLTABLES, para poder utilizar nuestras tablas de validación y de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Punto (c): Crear un Trabajo de Entrenamiento con AutoML\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1698090791632
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job creado: compute: azureml:/subscriptions/ba1f7bf8-2be6-4bed-b818-c745bda74905/resourceGroups/primer_proyecto/providers/Microsoft.MachineLearningServices/workspaces/primer_proyecto/computes/\n",
            "creation_context:\n",
            "  created_at: '2023-10-23T19:53:17.854583+00:00'\n",
            "  created_by: MAURICIO ALEJANDRO QUEZADA BUSTILLO\n",
            "  created_by_type: User\n",
            "display_name: frosty_ear_pgq4rdwm95\n",
            "experiment_name: automl-co2-emission\n",
            "id: azureml:/subscriptions/ba1f7bf8-2be6-4bed-b818-c745bda74905/resourceGroups/primer_proyecto/providers/Microsoft.MachineLearningServices/workspaces/primer_proyecto/jobs/frosty_ear_pgq4rdwm95\n",
            "limits:\n",
            "  enable_early_termination: true\n",
            "  max_concurrent_trials: 1\n",
            "  max_cores_per_trial: -1\n",
            "  max_nodes: 1\n",
            "  max_trials: 1000\n",
            "  timeout_minutes: 60\n",
            "  trial_timeout_minutes: 30\n",
            "log_verbosity: info\n",
            "name: frosty_ear_pgq4rdwm95\n",
            "outputs: {}\n",
            "primary_metric: normalized_root_mean_squared_error\n",
            "properties: {}\n",
            "resources:\n",
            "  instance_count: 1\n",
            "  instance_type: Standard_D2_v2\n",
            "  properties: {}\n",
            "  shm_size: 2g\n",
            "services:\n",
            "  Studio:\n",
            "    endpoint: https://ml.azure.com/runs/frosty_ear_pgq4rdwm95?wsid=/subscriptions/ba1f7bf8-2be6-4bed-b818-c745bda74905/resourcegroups/primer_proyecto/workspaces/primer_proyecto&tid=cc28633f-12b8-46cb-bc15-951dae239b4d\n",
            "  Tracking:\n",
            "    endpoint: azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/ba1f7bf8-2be6-4bed-b818-c745bda74905/resourceGroups/primer_proyecto/providers/Microsoft.MachineLearningServices/workspaces/primer_proyecto?\n",
            "status: NotStarted\n",
            "tags: {}\n",
            "target_column_name: CO2 Emissions(g/km)\n",
            "task: regression\n",
            "training:\n",
            "  enable_dnn_training: false\n",
            "  enable_model_explainability: true\n",
            "  enable_onnx_compatible_models: false\n",
            "  enable_stack_ensemble: true\n",
            "  enable_vote_ensemble: true\n",
            "  ensemble_model_download_timeout_minutes: 5\n",
            "  training_mode: auto\n",
            "training_data:\n",
            "  path: azureml://datastores/workspaceblobstore/paths/LocalUpload/ef5df662a2ac23fabc671d478f132895/train_data\n",
            "  type: mltable\n",
            "type: automl\n",
            "validation_data:\n",
            "  path: azureml://datastores/workspaceblobstore/paths/LocalUpload/b26beafe5078a539622779c46086b63f/valid_data\n",
            "  type: mltable\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import automl, Input, MLClient\n",
        "from azure.ai.ml.entities import ResourceConfiguration\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# Cargamos los datos (previamente separados) a un MLTable\n",
        "train_mltable_path = \"./train_data/\" \n",
        "valid_mltable_path = \"./valid_data/\" \n",
        "\n",
        "# Define los inputs de MLTable\n",
        "train_data_input = Input(type=AssetTypes.MLTABLE, path=train_mltable_path)\n",
        "valid_data_input = Input(type=AssetTypes.MLTABLE, path=valid_mltable_path)\n",
        "\n",
        "# Configuramos el job de AutoML para regresión\n",
        "experiment_name = 'automl-co2-emission'\n",
        "automl_job = automl.regression(\n",
        "    experiment_name=experiment_name,\n",
        "    training_data=train_data_input,\n",
        "    validation_data=valid_data_input,\n",
        "    target_column_name=\"CO2 Emissions(g/km)\",\n",
        "    primary_metric=\"normalized_root_mean_squared_error\"\n",
        ")\n",
        "\n",
        "# Configura límites y recursos\n",
        "automl_job.compute = cluster_name\n",
        "automl_job.set_limits(timeout_minutes=60)\n",
        "\n",
        "# Autenticación y envío del job\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client = MLClient.from_config(credential)\n",
        "returned_job = ml_client.jobs.create_or_update(automl_job)\n",
        "\n",
        "print(f\"Job creado: {returned_job}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "JUSTIFICACIÓN:\n",
        "    \n",
        "    *Utilizamos los parámetros por defecto que posee el Job, debido a que estamso trabajando con un modelo de regresión y esta no implica muchas carga y por ende se puede probar todos lo moedelos y encontrar el mejor, sin necesidad de mover parámetros del Job.\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Punto (d): Recuperar y Visualizar los Resultados del Trabajo con AutoML\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1698099758945
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "URL de seguimiento de MLflow: azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/ba1f7bf8-2be6-4bed-b818-c745bda74905/resourceGroups/primer_proyecto/providers/Microsoft.MachineLearningServices/workspaces/primer_proyecto\n",
            "<Run: data=<RunData: metrics={'explained_variance': 0.9968423656109591,\n",
            " 'mean_absolute_error': 1.960839788144388,\n",
            " 'mean_absolute_percentage_error': 0.8030106191525185,\n",
            " 'median_absolute_error': 1.4575644237046106,\n",
            " 'normalized_mean_absolute_error': 0.004602910300808422,\n",
            " 'normalized_median_absolute_error': 0.003421512731700964,\n",
            " 'normalized_root_mean_squared_error': 0.007739424688184539,\n",
            " 'normalized_root_mean_squared_log_error': 0.007782983700169502,\n",
            " 'r2_score': 0.996839722977584,\n",
            " 'root_mean_squared_error': 3.2969949171666135,\n",
            " 'root_mean_squared_log_error': 0.013113319526022143,\n",
            " 'spearman_correlation': 0.9981283121488365}, params={}, tags={'mlflow.parentRunId': 'good_diamond_8q33ypyzh7',\n",
            " 'mlflow.rootRunId': 'good_diamond_8q33ypyzh7',\n",
            " 'mlflow.runName': 'eager_nose_ctk78pc1',\n",
            " 'mlflow.source.name': 'automl_driver.py',\n",
            " 'mlflow.source.type': 'JOB',\n",
            " 'mlflow.user': 'MAURICIO ALEJANDRO QUEZADA BUSTILLO',\n",
            " 'model_explain_run_id': 'good_diamond_8q33ypyzh7_ModelExplain',\n",
            " 'model_explanation': 'True',\n",
            " 'model_rai': 'True'}>, info=<RunInfo: artifact_uri='azureml://eastus2.api.azureml.ms/mlflow/v2.0/subscriptions/ba1f7bf8-2be6-4bed-b818-c745bda74905/resourceGroups/primer_proyecto/providers/Microsoft.MachineLearningServices/workspaces/primer_proyecto/experiments/5171dae7-ecd3-4e1d-95de-ae6ebd187265/runs/good_diamond_8q33ypyzh7_40/artifacts', end_time=1698096561212, experiment_id='5171dae7-ecd3-4e1d-95de-ae6ebd187265', lifecycle_stage='active', run_id='good_diamond_8q33ypyzh7_40', run_name='eager_nose_ctk78pc1', run_uuid='good_diamond_8q33ypyzh7_40', start_time=1698096500011, status='FINISHED', user_id='858de858-9d33-41f4-ba7a-5a657073230a'>, inputs=<RunInputs: dataset_inputs=[]>>\n"
          ]
        }
      ],
      "source": [
        "# Importar las bibliotecas necesarias\n",
        "import mlflow\n",
        "from mlflow.tracking.client import MlflowClient\n",
        "from mlflow.artifacts import download_artifacts\n",
        "\n",
        "# --- (d) Información del Job y Best Run ---\n",
        "\n",
        "# 1. Obtener el trabajo\n",
        "job = ml_client.jobs.get(name=returned_job.name)\n",
        "\n",
        "# 2. Obtener la URL de seguimiento (tracking URI) de MLClient.\n",
        "# Esta URL es necesaria para acceder a la información del experimento y los runs en MLflow.\n",
        "MLFLOW_TRACKING_URI = ml_client.workspaces.get(\n",
        "    name=ml_client.workspace_name\n",
        ").mlflow_tracking_uri\n",
        "\n",
        "print(f\"URL de seguimiento de MLflow: {MLFLOW_TRACKING_URI}\")\n",
        "\n",
        "# 3. Configurar MLflow para usar la URL de seguimiento obtenida.\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "\n",
        "# 4. Inicializar el cliente de MLflow.\n",
        "mlflow_client = MlflowClient()\n",
        "\n",
        "# 5. Obtener el run principal del trabajo. En AutoML, este run tiene sub-runs para cada modelo probado.\n",
        "mlflow_parent_run = mlflow_client.get_run(job.name)\n",
        "\n",
        "# 6. Del run principal, extraer el ID del mejor sub-run (mejor modelo probado por AutoML).\n",
        "best_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]\n",
        "\n",
        "# 7. Usar el ID del mejor sub-run para obtener toda la información sobre ese run.\n",
        "best_run = mlflow_client.get_run(best_child_run_id)\n",
        "\n",
        "# Mostrar la información del mejor run.\n",
        "print(best_run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### ¿Qué modelos intentó probar AutoML?\n",
        "AutoML intentó probar varios algoritmos, algunos son:\n",
        "- LightGBM\n",
        "- XGBoostRegressor\n",
        "- ElasticNet\n",
        "- RandomForest\n",
        "- ExtremeRandomTrees\n",
        "- DecisionTree\n",
        "\n",
        "#### ¿El mejor modelo es preciso o no?\n",
        "El mejor modelo utilizado por AutoML es: LightGBM.\n",
        "\n",
        "Basándonos en las métricas proporcionadas:\n",
        "- R2 Score: 0.996839722977584\n",
        "- Correlación de Spearman: 0.9981283121488365\n",
        "\n",
        "Se pudo concluir que dicho modelo es el más adecuado por la alta precisión buscada para este modelo de regresión, poseyendo un R2 Score muy cercano a 1 que indica que el modelo desarrollado puede dar sentido y explicar una gran proporción de la variabilidad en los datos. Además, una correlación de Spearman bordeando al 1 infiere en una fuerte relación monótona entre las predicciones del sistema y los valores reales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Punto (e): Crear un Endpoint y Desplegar el Mejor Modelo\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1698101227167
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reg-10232239\n",
            "....................................................................................."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Check: endpoint reg-10232239 exists\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ManagedOnlineDeployment({'private_network_connection': None, 'provisioning_state': 'Succeeded', 'endpoint_name': 'reg-10232239', 'type': 'Managed', 'name': 'regression-deployment', 'description': None, 'tags': {}, 'properties': {'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/ba1f7bf8-2be6-4bed-b818-c745bda74905/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/od:64353576-ec82-4005-a1d0-bdf99309bf66:833f0f17-cb74-4411-a5ba-3e799668d98e?api-version=2023-04-01-preview'}, 'print_as_yaml': True, 'id': '/subscriptions/ba1f7bf8-2be6-4bed-b818-c745bda74905/resourceGroups/primer_proyecto/providers/Microsoft.MachineLearningServices/workspaces/primer_proyecto/onlineEndpoints/reg-10232239/deployments/regression-deployment', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/primer-proyecto/code/Users/mauricio.quezada', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f2c6fdc0f40>, 'model': '/subscriptions/ba1f7bf8-2be6-4bed-b818-c745bda74905/resourceGroups/primer_proyecto/providers/Microsoft.MachineLearningServices/workspaces/primer_proyecto/models/regression-model/versions/3', 'code_configuration': None, 'environment': None, 'environment_variables': {}, 'app_insights_enabled': False, 'scale_settings': <azure.ai.ml.entities._deployment.scale_settings.DefaultScaleSettings object at 0x7f2c6fdc1120>, 'request_settings': <azure.ai.ml.entities._deployment.deployment_settings.OnlineRequestSettings object at 0x7f2c6fdc1540>, 'liveness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7f2c6fdc1180>, 'readiness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7f2c6fdc1960>, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'Standard_E4s_v3', 'data_collector': None, 'egress_public_network_access': 'Enabled'})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        "    ProbeSettings,\n",
        ")\n",
        "\n",
        "# Creando un nombre de endpoint único con la fecha y hora actuales para evitar conflictos\n",
        "import datetime\n",
        "\n",
        "# Creando un nombre de endpoint único con la fecha y hora actuales para evitar conflictos\n",
        "online_endpoint_name = \"reg-\" + datetime.datetime.now().strftime(\"%m%d%H%M\")\n",
        "\n",
        "# verificar la longitud del nombre del endpoint\n",
        "assert 3 <= len(online_endpoint_name) <= 32, \"El nombre del endpoint no cumple con la longitud requerida.\"\n",
        "\n",
        "# crear un endpoint en línea\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"Endpoint online para desplegar el modelo de regresión\",\n",
        "    auth_mode=\"key\",\n",
        "    tags={\"type\": \"regression\"},\n",
        ")\n",
        "print(online_endpoint_name)\n",
        "\n",
        "ml_client.begin_create_or_update(endpoint).result()\n",
        "\n",
        "# Registramos el modelo de regresión que hemos entrenado\n",
        "model_name = \"regression-model\"\n",
        "model = Model(\n",
        "    path=f\"azureml://jobs/{best_run.info.run_id}/outputs/artifacts/outputs/mlflow-model/\",\n",
        "    name=model_name,\n",
        "    description=\"Modelo de regresión\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        ")\n",
        "registered_model = ml_client.models.create_or_update(model)\n",
        "\n",
        "# Desplegamos el modelo en el endpoint\n",
        "deployment = ManagedOnlineDeployment(\n",
        "    name=\"regression-deployment\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=registered_model.id,\n",
        "    instance_type=\"Standard_E4s_v3\",  # Puedes elegir otro tipo de instancia si lo prefieres\n",
        "    instance_count=1)\n",
        "ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Punto(f): Realizar una predicción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1698102420426
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[172.076099334576]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Datos de entrada basados en las columnas del CSV\n",
        "request_json = {\n",
        "    \"input_data\": {\n",
        "        \"columns\": [\"Make\", \"Model\", \"Vehicle Class\", \"Engine Size(L)\", \"Cylinders\", \"Transmission\", \"Fuel Type\", \"Fuel Consumption City (L/100 km)\", \"Fuel Consumption Hwy (L/100 km)\", \"Fuel Consumption Comb (L/100 km)\", \"Fuel Consumption Comb (mpg)\"],\n",
        "        \"data\": [{\"Make\": \"Toyota\", \"Model\": \"Corolla\", \"Vehicle Class\": \"COMPACT\", \"Engine Size(L)\": 1.8, \"Cylinders\": 4, \"Transmission\": \"Automatic\", \"Fuel Type\": \"Gasoline\", \"Fuel Consumption City (L/100 km)\": 8.5, \"Fuel Consumption Hwy (L/100 km)\": 6.2, \"Fuel Consumption Comb (L/100 km)\": 7.4, \"Fuel Consumption Comb (mpg)\": 38}]\n",
        "    }\n",
        "}\n",
        "\n",
        "request_file_name = \"sample_request_data.json\"\n",
        "with open(request_file_name, \"w\") as request_file:\n",
        "    json.dump(request_json, request_file)\n",
        "\n",
        "resp = ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    deployment_name=deployment.name,\n",
        "    request_file=request_file_name,\n",
        ")\n",
        "print(resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1698102618494
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'[172.076099334576]'\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import ssl\n",
        "\n",
        "def allowSelfSignedHttps(allowed):\n",
        "    # bypass the server certificate verification on client side\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
        "\n",
        "body = str.encode(json.dumps(request_json))\n",
        "\n",
        "url = 'https://reg-10232239.eastus2.inference.ml.azure.com/score'\n",
        "# Replace this with the primary/secondary key or AMLToken for the endpoint\n",
        "api_key = 'E8Khe5C4eC3zWFYYBC8kwgz3NFhfoF4t'\n",
        "if not api_key:\n",
        "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
        "\n",
        "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
        "# Remove this header to have the request observe the endpoint traffic rules\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'regression-deployment' }\n",
        "\n",
        "req = urllib.request.Request(url, body, headers)\n",
        "\n",
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
